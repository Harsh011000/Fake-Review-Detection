{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ce974e-1a43-4e58-ba32-17e47d033d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 17:59:02.845124: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-19 17:59:02.856504: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-19 17:59:02.876226: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-19 17:59:02.876280: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-19 17:59:02.886630: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-19 17:59:03.415738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "np.random.seed(1)\n",
    "\n",
    "# Download the tokenizer if you haven't already\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351d45af-27fd-42e0-aab4-a51d54ce5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "word_to_index = load('Embeddings/word_to_index.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8d1f33b-e7eb-4618-beb6-d9f86ec3adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():   \n",
    "    # Registering the Custom Embedding Layer\n",
    "    @tf.keras.utils.register_keras_serializable(package=\"CustomLayers\")\n",
    "    class SerializableEmbedding(Embedding):\n",
    "        def get_config(self):\n",
    "            config = super().get_config()\n",
    "            return config\n",
    "\n",
    "    model=tf.keras.models.load_model('Review Detector2.keras')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c345a1-f727-4f70-a2a9-00cf7f4f5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_pad(tokens, max_len=510, pad_value=0, unk_index=0):\n",
    "    # Convert words to indices using the dictionary, use unk_index if word not found\n",
    "    indexed_tokens=[]\n",
    "    for word in tokens:\n",
    "        if word in word_to_index.keys():\n",
    "            idx=word_to_index.get(word)\n",
    "            indexed_tokens.append(idx)\n",
    "    #indexed_tokens = [word_to_index.get(word, unk_index) for word in tokens]\n",
    "    \n",
    "    # Pad or truncate to the required length\n",
    "    if len(indexed_tokens) < max_len:\n",
    "        indexed_tokens += [pad_value] * (max_len - len(indexed_tokens))  # Pad\n",
    "    else:\n",
    "        indexed_tokens = indexed_tokens[:max_len]  # Truncate if too long\n",
    "    \n",
    "    return indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6fe3036-f49f-4478-be00-f5534345f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Example sentence\n",
    "    sentence = text.lower()\n",
    "    \n",
    "    # Tokenizing the sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "\n",
    "    indexed_tokens=convert_and_pad(tokens)\n",
    "\n",
    "    data=np.array(indexed_tokens).reshape(1,-1)\n",
    "\n",
    "    prediction=model.predict(data)\n",
    "    prediction=prediction[0][0]\n",
    "    if(prediction>0.5):\n",
    "        return [\"Human Written\",round(prediction*100,2)]\n",
    "    else:\n",
    "        return [\"Machine Generated\",round((1-prediction)*100,2)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfa2013c-3462-4da2-8d18-48a7ec41c606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8001\n",
      " * Running on http://172.21.168.162:8001\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:48503')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# Define API endpoint for predictions\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    review_text = data.get(\"review\", \"\")\n",
    "\n",
    "    if not review_text:\n",
    "        return jsonify({\"error\": \"No review provided\"}), 400\n",
    "\n",
    "    \n",
    "    # processed_input = preprocess_text(review_text)\n",
    "    #prediction = model.predict(processed_input)[0][0]\n",
    "    result = predict(review_text)\n",
    "\n",
    "    return jsonify({\"prediction\": result[0], \"score\": result[1]})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=8001, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f74f3ca-7c53-442e-b308-fec49d77ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
      "/bin/bash: -c: line 1: ` kill -9 <PID>'\n"
     ]
    }
   ],
   "source": [
    "! kill -9 <PID>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee7d4f4c-4f26-48db-be42-5155ab4e43e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 654, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:33185')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/post-data', methods=['POST'])\n",
    "def handle_post():\n",
    "    data = request.get_json()  # Get JSON data from request body\n",
    "    if not data:\n",
    "        return jsonify({'error': 'No data provided'}), 400\n",
    "\n",
    "    response = {\n",
    "        'message': 'Data received successfully!',\n",
    "        'received_data': data\n",
    "    }\n",
    "    return jsonify(response), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0adef8b7-bc0a-4489-aaf5-32a29d0ec242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `33185'\n",
      "/bin/bash: -c: line 1: ` grep<33185>'\n"
     ]
    }
   ],
   "source": [
    "! grep<33185>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abfdb1aa-1e43-4f17-8098-09038408eb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fnhgrhhigr', 'data']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(\"fnhgrhhigr data\")\n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91f3cec0-53b2-4f60-bb62-ac588a665568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[117493,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens=convert_and_pad(tokens[::-1])\n",
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58ade029-08f0-4b3c-af89-1c51aed8a00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79a5a924-62cc-4bd7-9bcf-b7407008d25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117493,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=np.array(indexed_tokens).reshape(1,-1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af3ec3c3-b348-4f20-ae7f-30fc92b19f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 510)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57881f5-168d-4ace-a776-1241bc6abf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 18:01:26.520487: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:26.668857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:26.668930: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:26.672477: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:26.672538: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:26.672556: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:27.261190: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:27.261258: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:27.261265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-19 18:01:27.261294: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:01:27.262666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 7 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model=loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68fcf86f-7b03-42ff-b0ff-8501611873ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5701cb8-f736-443b-9c17-67593f64aacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81013787]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df9e4bd3-4aaa-4b77-bb36-7dc9fc74734c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19 18:11:55.411224: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-19 18:11:55.422899: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-19 18:11:55.439379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-19 18:11:55.439453: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-19 18:11:55.449586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-19 18:11:56.328317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      " * Serving Flask app 'APi'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8001\n",
      " * Running on http://172.21.168.162:8001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "2025-03-19 18:11:59.286865: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-19 18:11:59.297601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-19 18:11:59.314504: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-19 18:11:59.314581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-19 18:11:59.324905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-19 18:11:59.854734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 135-272-429\n",
      "2025-03-19 18:12:06.412146: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.457236: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.457358: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.461475: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.461581: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.461621: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.576878: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.577002: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.577025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-03-19 18:12:06.577076: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-03-19 18:12:06.577114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1767 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/tensor/anaconda3/envs/tensor_check/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 7 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "127.0.0.1 - - [19/Mar/2025 18:12:07] \"POST /predict HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python APi.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b0ffbc-7432-4ff6-9ae4-5d4192f6ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- -----------\n",
      "absl-py                            2.1.0\n",
      "aiosignal                          1.3.1\n",
      "alembic                            1.14.0\n",
      "anyio                              4.2.0\n",
      "argon2-cffi                        21.3.0\n",
      "argon2-cffi-bindings               21.2.0\n",
      "asttokens                          2.0.5\n",
      "astunparse                         1.6.3\n",
      "async-lru                          2.0.4\n",
      "attrs                              24.3.0\n",
      "Babel                              2.11.0\n",
      "bayesian-optimization              2.0.1\n",
      "beautifulsoup4                     4.12.3\n",
      "bleach                             4.1.0\n",
      "blinker                            1.9.0\n",
      "Brotli                             1.0.9\n",
      "cachetools                         5.5.0\n",
      "certifi                            2024.6.2\n",
      "cffi                               1.16.0\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.1.7\n",
      "cloudpickle                        3.1.0\n",
      "colorama                           0.4.6\n",
      "colorlog                           6.9.0\n",
      "comm                               0.2.1\n",
      "ConfigSpace                        0.7.1\n",
      "contourpy                          1.2.1\n",
      "cupy-cuda12x                       13.3.0\n",
      "cycler                             0.12.1\n",
      "databricks-sdk                     0.36.0\n",
      "debugpy                            1.6.7\n",
      "decorator                          5.1.1\n",
      "defusedxml                         0.7.1\n",
      "Deprecated                         1.2.14\n",
      "docker                             7.1.0\n",
      "executing                          0.8.3\n",
      "fastjsonschema                     2.16.2\n",
      "fastrlock                          0.8.2\n",
      "filelock                           3.16.1\n",
      "Flask                              3.0.3\n",
      "flatbuffers                        24.3.25\n",
      "fonttools                          4.53.1\n",
      "frozenlist                         1.5.0\n",
      "fsspec                             2024.10.0\n",
      "future                             1.0.0\n",
      "gast                               0.6.0\n",
      "gitdb                              4.0.11\n",
      "GitPython                          3.1.43\n",
      "google-auth                        2.36.0\n",
      "google-pasta                       0.2.0\n",
      "graphene                           3.4.3\n",
      "graphql-core                       3.2.5\n",
      "graphql-relay                      3.2.0\n",
      "greenlet                           3.1.1\n",
      "grpcio                             1.64.1\n",
      "gunicorn                           23.0.0\n",
      "h11                                0.14.0\n",
      "h5py                               3.11.0\n",
      "hpbandster                         0.7.4\n",
      "hyperopt                           0.2.7\n",
      "idna                               3.7\n",
      "imageio                            2.35.1\n",
      "importlib_metadata                 8.5.0\n",
      "ipykernel                          6.28.0\n",
      "ipython                            8.25.0\n",
      "itsdangerous                       2.2.0\n",
      "jedi                               0.18.1\n",
      "Jinja2                             3.1.4\n",
      "joblib                             1.4.2\n",
      "json5                              0.9.6\n",
      "jsonschema                         4.19.2\n",
      "jsonschema-specifications          2023.7.1\n",
      "jupyter_client                     8.6.0\n",
      "jupyter_core                       5.7.2\n",
      "jupyter-events                     0.10.0\n",
      "jupyter-lsp                        2.2.0\n",
      "jupyter_server                     2.14.1\n",
      "jupyter_server_terminals           0.4.4\n",
      "jupyterlab                         4.0.11\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab_server                  2.25.1\n",
      "keras                              3.4.1\n",
      "keras-tuner                        1.4.7\n",
      "kiwisolver                         1.4.5\n",
      "kt-legacy                          1.0.5\n",
      "lazy_loader                        0.4\n",
      "libclang                           18.1.1\n",
      "Mako                               1.3.6\n",
      "Markdown                           3.6\n",
      "markdown-it-py                     3.0.0\n",
      "MarkupSafe                         2.1.3\n",
      "matplotlib                         3.9.1\n",
      "matplotlib-inline                  0.1.6\n",
      "mdurl                              0.1.2\n",
      "mistune                            2.0.4\n",
      "ml-dtypes                          0.3.2\n",
      "mlflow                             2.17.2\n",
      "mlflow-skinny                      2.17.2\n",
      "more-itertools                     10.5.0\n",
      "msgpack                            1.1.0\n",
      "namex                              0.0.8\n",
      "nbclient                           0.8.0\n",
      "nbconvert                          7.10.0\n",
      "nbformat                           5.9.2\n",
      "nest-asyncio                       1.6.0\n",
      "netifaces                          0.11.0\n",
      "networkx                           3.3\n",
      "nltk                               3.9.1\n",
      "notebook                           7.0.8\n",
      "notebook_shim                      0.2.3\n",
      "numpy                              1.26.4\n",
      "nvidia-cublas-cu12                 12.3.4.1\n",
      "nvidia-cuda-cupti-cu12             12.3.101\n",
      "nvidia-cuda-nvcc-cu12              12.3.107\n",
      "nvidia-cuda-nvrtc-cu12             12.3.107\n",
      "nvidia-cuda-runtime-cu12           12.3.101\n",
      "nvidia-cudnn-cu12                  8.9.7.29\n",
      "nvidia-cufft-cu12                  11.0.12.1\n",
      "nvidia-curand-cu12                 10.3.4.107\n",
      "nvidia-cusolver-cu12               11.5.4.101\n",
      "nvidia-cusparse-cu12               12.2.0.103\n",
      "nvidia-nccl-cu12                   2.19.3\n",
      "nvidia-nvjitlink-cu12              12.3.101\n",
      "opencv-python                      4.10.0.84\n",
      "opentelemetry-api                  1.28.1\n",
      "opentelemetry-sdk                  1.28.1\n",
      "opentelemetry-semantic-conventions 0.49b1\n",
      "opt-einsum                         3.3.0\n",
      "optree                             0.11.0\n",
      "optuna                             4.1.0\n",
      "outcome                            1.3.0.post0\n",
      "overrides                          7.4.0\n",
      "packaging                          24.1\n",
      "pandas                             2.2.2\n",
      "pandocfilters                      1.5.0\n",
      "parso                              0.8.3\n",
      "patsy                              1.0.1\n",
      "pexpect                            4.8.0\n",
      "pillow                             10.4.0\n",
      "pip                                24.1.1\n",
      "platformdirs                       3.10.0\n",
      "prometheus-client                  0.14.1\n",
      "prompt-toolkit                     3.0.43\n",
      "protobuf                           4.25.3\n",
      "psutil                             5.9.0\n",
      "ptyprocess                         0.7.0\n",
      "pure-eval                          0.2.2\n",
      "py4j                               0.10.9.8\n",
      "pyarrow                            17.0.0\n",
      "pyasn1                             0.6.1\n",
      "pyasn1_modules                     0.4.1\n",
      "pycparser                          2.21\n",
      "Pygments                           2.15.1\n",
      "pyparsing                          3.1.2\n",
      "Pyro4                              4.82\n",
      "PySocks                            1.7.1\n",
      "python-dateutil                    2.9.0.post0\n",
      "python-dotenv                      1.0.1\n",
      "python-json-logger                 2.0.7\n",
      "pytz                               2024.1\n",
      "PyYAML                             6.0.1\n",
      "pyzmq                              25.1.2\n",
      "ray                                2.42.1\n",
      "referencing                        0.30.2\n",
      "regex                              2024.11.6\n",
      "requests                           2.32.3\n",
      "rfc3339-validator                  0.1.4\n",
      "rfc3986-validator                  0.1.1\n",
      "rich                               13.7.1\n",
      "rpds-py                            0.10.6\n",
      "rsa                                4.9\n",
      "scikit-image                       0.24.0\n",
      "scikit-learn                       1.5.1\n",
      "scipy                              1.14.0\n",
      "seaborn                            0.13.2\n",
      "selenium                           4.27.1\n",
      "Send2Trash                         1.8.2\n",
      "serpent                            1.41\n",
      "setuptools                         69.5.1\n",
      "six                                1.16.0\n",
      "smmap                              5.0.1\n",
      "sniffio                            1.3.0\n",
      "sortedcontainers                   2.4.0\n",
      "soupsieve                          2.5\n",
      "SQLAlchemy                         2.0.36\n",
      "sqlparse                           0.5.1\n",
      "stack-data                         0.2.0\n",
      "statsmodels                        0.14.4\n",
      "tabulate                           0.9.0\n",
      "tensorboard                        2.16.2\n",
      "tensorboard-data-server            0.7.2\n",
      "tensorboardX                       2.6.2.2\n",
      "tensorflow                         2.16.2\n",
      "tensorflow-io-gcs-filesystem       0.37.1\n",
      "termcolor                          2.4.0\n",
      "terminado                          0.17.1\n",
      "threadpoolctl                      3.5.0\n",
      "tifffile                           2024.8.30\n",
      "tinycss2                           1.2.1\n",
      "tornado                            6.4.1\n",
      "tqdm                               4.67.1\n",
      "traitlets                          5.14.3\n",
      "trio                               0.28.0\n",
      "trio-websocket                     0.11.1\n",
      "typing_extensions                  4.11.0\n",
      "tzdata                             2024.1\n",
      "urllib3                            2.2.2\n",
      "wcwidth                            0.2.5\n",
      "webdriver-manager                  4.0.2\n",
      "webencodings                       0.5.1\n",
      "websocket-client                   1.8.0\n",
      "Werkzeug                           3.0.3\n",
      "wheel                              0.43.0\n",
      "wrapt                              1.16.0\n",
      "wsproto                            1.2.0\n",
      "zipp                               3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
